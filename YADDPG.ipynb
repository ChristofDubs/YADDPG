{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import tensorflow as tf\n",
    "import json, sys, os\n",
    "from os import path\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# hyperparameters\n",
    "gamma = 0.99\t\t\t\t# reward discount factor\n",
    "lr_actor = 1e-3\t\t\t\t# learning rate for the actor\n",
    "lr_critic = 1e-3\t\t\t# learning rate for the critic\n",
    "lr_decay = 1\t\t\t\t# learning rate decay (per episode)\n",
    "l2_reg_actor = 5e-7\t\t\t# L2 regularization factor for the actor\n",
    "l2_reg_critic = 5e-7\t\t# L2 regularization factor for the critic\n",
    "num_episodes = 1000\t\t# number of episodes\n",
    "max_steps_ep = 10000\t# default max number of steps per episode (unless env has a lower hardcoded limit)\n",
    "tau = 1e-2\t\t\t\t# soft target update rate\n",
    "train_every = 1 # number of steps to run the policy (and collect experience) before updating network weights\n",
    "replay_memory_capacity = int(1e5)\t# capacity of experience replay memory\n",
    "minibatch_size = 1024\t# size of minibatch from experience replay memory for updates\n",
    "initial_noise_scale = 0.1\t# scale of the exploration noise process (1.0 is the range of each action dimension)\n",
    "noise_decay = 0.99\t\t# decay rate (per episode) of the scale of the exploration noise process\n",
    "exploration_mu = 0.0\t# mu parameter for the exploration noise process: dXt = theta*(mu-Xt)*dt + sigma*dWt\n",
    "exploration_theta = 0.15 # theta parameter for the exploration noise process: dXt = theta*(mu-Xt)*dt + sigma*dWt\n",
    "exploration_sigma = 0.2\t# sigma parameter for the exploration noise process: dXt = theta*(mu-Xt\t)*dt + sigma*dWt\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "state_dim = np.prod(np.array(env.observation_space.shape)) \t# Get total number of dimensions in state\n",
    "action_dim = np.prod(np.array(env.action_space.shape))\t\t# Assuming continuous action space\n",
    "\n",
    "critic_network_spec = [{'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': 1, 'activation': None}]\n",
    "\n",
    "actor_network_spec =  [{'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': 8, 'activation': tf.nn.relu},\n",
    "                       {'units': action_dim, 'activation': tf.nn.tanh}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experience(object):\n",
    "    def __init__(self, bufferSize):\n",
    "        self.buffer = deque([],bufferSize)\n",
    "\n",
    "    def recall(self, batchSize):\n",
    "        batchSize = min(len(self.buffer), batchSize)\n",
    "        \n",
    "        batch = random.sample(self.buffer, batchSize)\n",
    "    \n",
    "        S = np.asarray([sample[0] for sample in batch]).reshape(batchSize, -1)\n",
    "        A = np.asarray([sample[1] for sample in batch]).reshape(batchSize, -1)\n",
    "        R = np.asarray([sample[2] for sample in batch]).reshape(batchSize)\n",
    "        S_dash = np.asarray([sample[3] for sample in batch]).reshape(batchSize, -1)\n",
    "        not_terminal = np.asarray([sample[4] for sample in batch]).reshape(batchSize)\n",
    "\n",
    "        return S, A, R, S_dash, not_terminal\n",
    "        \n",
    "    def store(self, state, action, reward, nextState, not_terminal):\n",
    "        self.buffer.append([state, action, reward, nextState, not_terminal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OU(object):\n",
    "    def __init__(self, dim, mu, theta, sigma):\n",
    "        self.dim = dim\n",
    "        self.mu, self.theta, self.sigma = mu, theta, sigma\n",
    "        self.noise_process = np.zeros(dim)\n",
    "\n",
    "    def get_noise(self):\n",
    "        self.noise_process = exploration_theta * (self.mu - self.noise_process) + self.sigma * np.random.randn(self.dim)\n",
    "        return self.noise_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, input_shape, spec, scope, trainable):\n",
    "        self.spec, self.scope, self.trainable = spec, scope, trainable\n",
    "        \n",
    "        self.get_forward_pass_op(tf.placeholder(dtype=tf.float32, shape=input_shape), False)\n",
    "        self.vars =  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope)\n",
    "\n",
    "    def get_forward_pass_op(self, inp, reuse=True):\n",
    "        with tf.variable_scope(self.scope, reuse=reuse):\n",
    "            for layer in self.spec:\n",
    "                inp = tf.layers.dense(inp, layer['units'], activation=layer['activation'], trainable=self.trainable)\n",
    "                \n",
    "        return inp\n",
    "\n",
    "    def get_target_train_op(self, target_network, tau):\n",
    "        update_ops = []\n",
    "        for i, var in enumerate(self.vars):\n",
    "            update_op = var.assign(tau * target_network.vars[i] + (1 - tau) * var)\n",
    "            update_ops.append(update_op)\n",
    "\n",
    "        return tf.group(*update_ops)\n",
    "    \n",
    "    def sum_weights(self):\n",
    "        return tf.add_n([tf.nn.l2_loss(var) for var in self.vars if not 'bias' in var.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, env):\n",
    "        self.sess = tf.Session()\n",
    "        self.env = env\n",
    "        \n",
    "        # Ornsteinâ€“Uhlenbeck process\n",
    "        self.OU = OU(action_dim, exploration_mu, exploration_theta, exploration_sigma)\n",
    "        \n",
    "        # experience replay\n",
    "        self.replay_memory = Experience(int(1e5))\n",
    "\n",
    "        # episode counter\n",
    "        self.episodes = tf.Variable(0.0, trainable=False)\n",
    "        self.episode_inc_op = self.episodes.assign_add(1)\n",
    "        \n",
    "        # tf placeholders\n",
    "        self.state_ph = tf.placeholder(dtype=tf.float32, shape=[None,state_dim])\n",
    "        self.action_ph = tf.placeholder(dtype=tf.float32, shape=[None,action_dim])\n",
    "        self.reward_ph = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "        self.next_state_ph = tf.placeholder(dtype=tf.float32, shape=[None,state_dim])\n",
    "        self.is_not_terminal_ph = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "        \n",
    "        # set up the networks\n",
    "        critic_network = Network([None, state_dim + action_dim], critic_network_spec, 'critic_net', trainable=True)\n",
    "        actor_network = Network([None, state_dim], actor_network_spec, 'actor_net', trainable=True)\n",
    "        slow_critic_network = Network([None, state_dim + action_dim], critic_network_spec, 'slow_critic_net', trainable=False)\n",
    "        slow_actor_network = Network([None, state_dim], actor_network_spec, 'slow_actor_net', trainable=False)\n",
    "\n",
    "        # actors        \n",
    "        self.policy_op = actor_network.get_forward_pass_op(self.state_ph) * 4\n",
    "        slow_target_next_actions = slow_actor_network.get_forward_pass_op(self.next_state_ph)\n",
    "        \n",
    "        # critics\n",
    "        critic_off_pol = critic_network.get_forward_pass_op(tf.concat([self.state_ph, self.action_ph], axis=1))\n",
    "        critic_on_pol = critic_network.get_forward_pass_op(tf.concat([self.state_ph, self.policy_op], axis=1))\n",
    "        slow_q_values_next = slow_critic_network.get_forward_pass_op(tf.concat([self.next_state_ph, slow_target_next_actions], axis=1))\n",
    "        \n",
    "        # train critic        \n",
    "        targets = tf.expand_dims(self.reward_ph, 1) + tf.expand_dims(self.is_not_terminal_ph, 1) * gamma * slow_q_values_next\n",
    "        td_errors = targets - critic_off_pol\n",
    "        critic_loss = tf.reduce_mean(tf.square(td_errors)) + l2_reg_critic * critic_network.sum_weights()\n",
    "        self.critic_train_op = tf.train.AdamOptimizer(lr_critic * lr_decay ** self.episodes).minimize(critic_loss)\n",
    "        \n",
    "        # train actor\n",
    "        actor_loss = -1 * tf.reduce_mean(critic_on_pol) + l2_reg_actor * actor_network.sum_weights()\n",
    "        self.actor_train_op = tf.train.AdamOptimizer(lr_actor * lr_decay ** self.episodes).minimize(actor_loss, var_list=actor_network.vars)\n",
    "        \n",
    "        # train slow networks\n",
    "        self.slow_actor_train_op = slow_actor_network.get_target_train_op(actor_network, tau)\n",
    "        self.slow_critic_train_op = slow_critic_network.get_target_train_op(critic_network, tau)\n",
    "\n",
    "        self.noise_scale = initial_noise_scale\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def act(self, state, stochastic=True):\n",
    "        action = self.sess.run(self.policy_op, feed_dict = {self.state_ph: state})\n",
    "\n",
    "        if stochastic:\n",
    "            self.noise_scale = (initial_noise_scale * noise_decay ** self.sess.run(self.episodes)) * (self.env.action_space.high - self.env.action_space.low)\n",
    "            action += self.noise_scale * self.OU.get_noise()\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def train(self):\n",
    "        # grab N (s,a,r,s') tuples from replay memory\n",
    "        S, A, R, S_dash, not_terminal = self.replay_memory.recall(minibatch_size)\n",
    "\n",
    "        # update the critic and actor params using mean-square value error and deterministic policy gradient, respectively\n",
    "        self.sess.run(self.critic_train_op, feed_dict = {self.state_ph: S, self.action_ph: A, self.reward_ph: R, self.next_state_ph: S_dash, self.is_not_terminal_ph: not_terminal})\n",
    "        self.sess.run(self.actor_train_op, feed_dict = {self.state_ph: S})\n",
    "\n",
    "        # update slow actor and critic targets towards current actor and critic\n",
    "        self.sess.run([self.slow_actor_train_op, self.slow_critic_train_op])\n",
    "        \n",
    "    def increment_episode(self):\n",
    "        self.sess.run(self.episode_inc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0, Reward: -1810.096, Steps: 200\n",
      "Episode  1, Reward: -1585.307, Steps: 200\n",
      "Episode  2, Reward: -1776.643, Steps: 200\n",
      "Episode  3, Reward: -1592.150, Steps: 200\n",
      "Episode  4, Reward: -1820.844, Steps: 200\n",
      "Episode  5, Reward: -1641.447, Steps: 200\n",
      "Episode  6, Reward: -1213.997, Steps: 200\n",
      "Episode  7, Reward: -1507.079, Steps: 200\n",
      "Episode  8, Reward: -1520.788, Steps: 200\n",
      "Episode  9, Reward: -1482.488, Steps: 200\n",
      "Episode 10, Reward: -1589.147, Steps: 200\n",
      "Episode 11, Reward: -1072.305, Steps: 200\n",
      "Episode 12, Reward: -1521.754, Steps: 200\n",
      "Episode 13, Reward: -1400.231, Steps: 200\n",
      "Episode 14, Reward: -1083.124, Steps: 200\n",
      "Episode 15, Reward: -1163.005, Steps: 200\n",
      "Episode 16, Reward: -1052.372, Steps: 200\n",
      "Episode 17, Reward: -877.601, Steps: 200\n",
      "Episode 18, Reward: -1497.745, Steps: 200\n",
      "Episode 19, Reward:  -7.678, Steps: 200\n",
      "Episode 20, Reward: -538.713, Steps: 200\n",
      "Episode 21, Reward: -913.999, Steps: 200\n",
      "Episode 22, Reward: -1055.146, Steps: 200\n",
      "Episode 23, Reward: -1061.796, Steps: 200\n",
      "Episode 24, Reward: -266.581, Steps: 200\n",
      "Episode 25, Reward: -999.995, Steps: 200\n",
      "Episode 26, Reward: -380.350, Steps: 200\n",
      "Episode 27, Reward: -134.445, Steps: 200\n",
      "Episode 28, Reward: -120.650, Steps: 200\n",
      "Episode 29, Reward: -1314.166, Steps: 200\n",
      "Episode 30, Reward: -1620.905, Steps: 200\n",
      "Episode 31, Reward: -1156.069, Steps: 200\n",
      "Episode 32, Reward: -10.322, Steps: 200\n",
      "Episode 33, Reward: -135.044, Steps: 200\n",
      "Episode 34, Reward: -237.171, Steps: 200\n",
      "Episode 35, Reward: -1489.594, Steps: 200\n",
      "Episode 36, Reward: -1516.044, Steps: 200\n",
      "Episode 37, Reward:  -5.451, Steps: 200\n",
      "Episode 38, Reward: -1385.902, Steps: 200\n",
      "Episode 39, Reward: -1339.249, Steps: 200\n",
      "Episode 40, Reward: -1139.129, Steps: 200\n",
      "Episode 41, Reward: -1546.733, Steps: 200\n",
      "Episode 42, Reward: -248.714, Steps: 200\n",
      "Episode 43, Reward:  -1.611, Steps: 200\n",
      "Episode 44, Reward: -129.361, Steps: 200\n",
      "Episode 45, Reward: -1189.525, Steps: 200\n",
      "Episode 46, Reward: -1326.825, Steps: 200\n",
      "Episode 47, Reward: -1232.502, Steps: 200\n",
      "Episode 48, Reward:  -2.852, Steps: 200\n",
      "Episode 49, Reward:  -1.681, Steps: 200\n",
      "Episode 50, Reward: -1177.118, Steps: 200\n",
      "Episode 51, Reward: -1091.540, Steps: 200\n",
      "Episode 52, Reward: -1144.747, Steps: 200\n",
      "Episode 53, Reward: -523.546, Steps: 200\n",
      "Episode 54, Reward: -136.444, Steps: 200\n",
      "Episode 55, Reward: -1494.272, Steps: 200\n",
      "Episode 56, Reward: -262.664, Steps: 200\n",
      "Episode 57, Reward: -404.341, Steps: 200\n",
      "Episode 58, Reward: -128.951, Steps: 200\n",
      "Episode 59, Reward: -257.366, Steps: 200\n",
      "Episode 60, Reward: -130.423, Steps: 200\n",
      "Episode 61, Reward: -266.975, Steps: 200\n",
      "Episode 62, Reward: -256.398, Steps: 200\n",
      "Episode 63, Reward: -129.330, Steps: 200\n",
      "Episode 64, Reward: -122.132, Steps: 200\n",
      "Episode 65, Reward: -127.380, Steps: 200\n",
      "Episode 66, Reward:  -2.203, Steps: 200\n",
      "Episode 67, Reward: -384.858, Steps: 200\n",
      "Episode 68, Reward: -240.072, Steps: 200\n",
      "Episode 69, Reward: -123.564, Steps: 200\n",
      "Episode 70, Reward: -127.549, Steps: 200\n",
      "Episode 71, Reward: -132.004, Steps: 200\n",
      "Episode 72, Reward: -227.517, Steps: 200\n",
      "Episode 73, Reward:  -2.168, Steps: 200\n",
      "Episode 74, Reward: -114.169, Steps: 200\n",
      "Episode 75, Reward:  -2.140, Steps: 200\n",
      "Episode 76, Reward: -254.296, Steps: 200\n",
      "Episode 77, Reward: -127.387, Steps: 200\n",
      "Episode 78, Reward: -117.315, Steps: 200\n",
      "Episode 79, Reward: -127.329, Steps: 200\n",
      "Episode 80, Reward: -246.256, Steps: 200\n",
      "Episode 81, Reward:  -3.232, Steps: 200\n",
      "Episode 82, Reward: -384.499, Steps: 200\n",
      "Episode 83, Reward: -136.691, Steps: 200\n",
      "Episode 84, Reward: -121.761, Steps: 200\n",
      "Episode 85, Reward: -128.161, Steps: 200\n",
      "Episode 86, Reward: -390.867, Steps: 200\n",
      "Episode 87, Reward: -117.673, Steps: 200\n",
      "Episode 88, Reward: -132.749, Steps: 200\n",
      "Episode 89, Reward: -130.139, Steps: 200\n",
      "Episode 90, Reward: -126.543, Steps: 200\n",
      "Episode 91, Reward: -127.590, Steps: 200\n",
      "Episode 92, Reward: -256.097, Steps: 200\n",
      "Episode 93, Reward: -130.148, Steps: 200\n",
      "Episode 94, Reward:  -1.646, Steps: 200\n",
      "Episode 95, Reward: -352.577, Steps: 200\n",
      "Episode 96, Reward: -124.686, Steps: 200\n",
      "Episode 97, Reward: -260.941, Steps: 200\n",
      "Episode 98, Reward: -127.131, Steps: 200\n",
      "Episode 99, Reward: -436.124, Steps: 200\n",
      "Episode 100, Reward: -265.899, Steps: 200\n",
      "Episode 101, Reward: -116.743, Steps: 200\n",
      "Episode 102, Reward: -243.873, Steps: 200\n",
      "Episode 103, Reward: -1492.788, Steps: 200\n",
      "Episode 104, Reward: -243.345, Steps: 200\n",
      "Episode 105, Reward: -133.672, Steps: 200\n",
      "Episode 106, Reward: -136.176, Steps: 200\n",
      "Episode 107, Reward: -259.834, Steps: 200\n",
      "Episode 108, Reward: -120.860, Steps: 200\n",
      "Episode 109, Reward: -1491.448, Steps: 200\n",
      "Episode 110, Reward: -130.046, Steps: 200\n",
      "Episode 111, Reward: -129.590, Steps: 200\n",
      "Episode 112, Reward: -243.766, Steps: 200\n",
      "Episode 113, Reward: -130.571, Steps: 200\n",
      "Episode 114, Reward: -125.339, Steps: 200\n",
      "Episode 115, Reward: -224.844, Steps: 200\n",
      "Episode 116, Reward: -271.853, Steps: 200\n",
      "Episode 117, Reward: -128.750, Steps: 200\n",
      "Episode 118, Reward: -116.609, Steps: 200\n",
      "Episode 119, Reward: -128.173, Steps: 200\n",
      "Episode 120, Reward: -261.072, Steps: 200\n",
      "Episode 121, Reward: -130.335, Steps: 200\n",
      "Episode 122, Reward: -135.426, Steps: 200\n",
      "Episode 123, Reward: -321.372, Steps: 200\n",
      "Episode 124, Reward: -125.551, Steps: 200\n",
      "Episode 125, Reward: -269.748, Steps: 200\n",
      "Episode 126, Reward: -129.929, Steps: 200\n",
      "Episode 127, Reward: -128.896, Steps: 200\n",
      "Episode 128, Reward: -124.814, Steps: 200\n",
      "Episode 129, Reward: -247.054, Steps: 200\n",
      "Episode 130, Reward:  -0.785, Steps: 200\n",
      "Episode 131, Reward: -255.492, Steps: 200\n",
      "Episode 132, Reward: -128.283, Steps: 200\n",
      "Episode 133, Reward: -116.977, Steps: 200\n",
      "Episode 134, Reward: -1491.220, Steps: 200\n",
      "Episode 135, Reward: -1493.120, Steps: 200\n",
      "Episode 136, Reward: -255.753, Steps: 200\n",
      "Episode 137, Reward: -1496.023, Steps: 200\n",
      "Episode 138, Reward: -267.982, Steps: 200\n",
      "Episode 139, Reward: -251.451, Steps: 200\n",
      "Episode 140, Reward: -265.924, Steps: 200\n",
      "Episode 141, Reward: -261.942, Steps: 200\n",
      "Episode 142, Reward: -473.132, Steps: 200\n",
      "Episode 143, Reward: -129.563, Steps: 200\n",
      "Episode 144, Reward: -126.436, Steps: 200\n",
      "Episode 145, Reward: -123.514, Steps: 200\n",
      "Episode 146, Reward:  -0.870, Steps: 200\n",
      "Episode 147, Reward: -120.579, Steps: 200\n",
      "Episode 148, Reward:  -1.739, Steps: 200\n",
      "Episode 149, Reward: -376.151, Steps: 200\n",
      "Episode 150, Reward: -381.789, Steps: 200\n",
      "Episode 151, Reward: -274.222, Steps: 200\n",
      "Episode 152, Reward:  -0.366, Steps: 200\n",
      "Episode 153, Reward: -258.082, Steps: 200\n",
      "Episode 154, Reward: -270.028, Steps: 200\n",
      "Episode 155, Reward: -277.181, Steps: 200\n",
      "Episode 156, Reward: -114.300, Steps: 200\n",
      "Episode 157, Reward: -126.215, Steps: 200\n",
      "Episode 158, Reward: -259.492, Steps: 200\n",
      "Episode 159, Reward: -125.355, Steps: 200\n",
      "Episode 160, Reward: -246.094, Steps: 200\n",
      "Episode 161, Reward: -135.983, Steps: 200\n",
      "Episode 162, Reward: -377.049, Steps: 200\n",
      "Episode 163, Reward: -118.707, Steps: 200\n",
      "Episode 164, Reward: -124.312, Steps: 200\n",
      "Episode 165, Reward: -126.980, Steps: 200\n",
      "Episode 166, Reward: -128.493, Steps: 200\n",
      "Episode 167, Reward: -352.556, Steps: 200\n",
      "Episode 168, Reward: -131.772, Steps: 200\n",
      "Episode 169, Reward: -128.547, Steps: 200\n",
      "Episode 170, Reward: -371.651, Steps: 200\n",
      "Episode 171, Reward: -126.067, Steps: 200\n",
      "Episode 172, Reward: -127.704, Steps: 200\n",
      "Episode 173, Reward: -369.598, Steps: 200\n",
      "Episode 174, Reward: -117.910, Steps: 200\n",
      "Episode 175, Reward: -229.791, Steps: 200\n",
      "Episode 176, Reward:  -2.887, Steps: 200\n",
      "Episode 177, Reward: -336.422, Steps: 200\n",
      "Episode 178, Reward: -124.103, Steps: 200\n",
      "Episode 179, Reward: -242.966, Steps: 200\n",
      "Episode 180, Reward: -387.980, Steps: 200\n",
      "Episode 181, Reward: -125.159, Steps: 200\n",
      "Episode 182, Reward: -116.920, Steps: 200\n",
      "Episode 183, Reward: -128.521, Steps: 200\n",
      "Episode 184, Reward: -240.320, Steps: 200\n",
      "Episode 185, Reward: -128.413, Steps: 200\n",
      "Episode 186, Reward: -123.939, Steps: 200\n",
      "Episode 187, Reward:  -1.159, Steps: 200\n",
      "Episode 188, Reward: -246.186, Steps: 200\n",
      "Episode 189, Reward:  -0.171, Steps: 200\n",
      "Episode 190, Reward: -118.152, Steps: 200\n",
      "Episode 191, Reward: -235.398, Steps: 200\n",
      "Episode 192, Reward: -118.292, Steps: 200\n",
      "Episode 193, Reward: -363.319, Steps: 200\n",
      "Episode 194, Reward: -127.445, Steps: 200\n",
      "Episode 195, Reward: -246.204, Steps: 200\n",
      "Episode 196, Reward: -123.366, Steps: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 197, Reward: -241.736, Steps: 200\n",
      "Episode 198, Reward: -256.892, Steps: 200\n",
      "Episode 199, Reward: -131.153, Steps: 200\n",
      "Episode 200, Reward: -307.568, Steps: 200\n",
      "Episode 201, Reward: -120.981, Steps: 200\n",
      "Episode 202, Reward: -130.985, Steps: 200\n",
      "Episode 203, Reward: -121.080, Steps: 200\n",
      "Episode 204, Reward: -126.730, Steps: 200\n",
      "Episode 205, Reward: -129.360, Steps: 200\n",
      "Episode 206, Reward: -130.970, Steps: 200\n",
      "Episode 207, Reward: -122.020, Steps: 200\n",
      "Episode 208, Reward: -119.665, Steps: 200\n",
      "Episode 209, Reward:  -0.441, Steps: 200\n",
      "Episode 210, Reward: -125.703, Steps: 200\n",
      "Episode 211, Reward: -121.232, Steps: 200\n",
      "Episode 212, Reward: -121.071, Steps: 200\n",
      "Episode 213, Reward:  -0.481, Steps: 200\n",
      "Episode 214, Reward: -378.245, Steps: 200\n",
      "Episode 215, Reward:  -0.254, Steps: 200\n",
      "Episode 216, Reward:  -1.629, Steps: 200\n",
      "Episode 217, Reward: -120.162, Steps: 200\n",
      "Episode 218, Reward: -1490.886, Steps: 200\n",
      "Episode 219, Reward: -280.640, Steps: 200\n",
      "Episode 220, Reward: -120.978, Steps: 200\n",
      "Episode 221, Reward: -129.278, Steps: 200\n",
      "Episode 222, Reward:  -0.228, Steps: 200\n",
      "Episode 223, Reward: -237.210, Steps: 200\n",
      "Episode 224, Reward: -240.442, Steps: 200\n",
      "Episode 225, Reward: -130.449, Steps: 200\n",
      "Episode 226, Reward: -388.038, Steps: 200\n",
      "Episode 227, Reward: -119.383, Steps: 200\n",
      "Episode 228, Reward: -438.671, Steps: 200\n",
      "Episode 229, Reward:  -2.928, Steps: 200\n",
      "Episode 230, Reward: -113.739, Steps: 200\n",
      "Episode 231, Reward: -120.763, Steps: 200\n",
      "Episode 232, Reward: -124.158, Steps: 200\n",
      "Episode 233, Reward:  -2.316, Steps: 200\n",
      "Episode 234, Reward: -266.612, Steps: 200\n",
      "Episode 235, Reward: -364.831, Steps: 200\n",
      "Episode 236, Reward: -125.119, Steps: 200\n",
      "Episode 237, Reward: -129.017, Steps: 200\n",
      "Episode 238, Reward: -125.056, Steps: 200\n",
      "Episode 239, Reward: -113.604, Steps: 200\n",
      "Episode 240, Reward: -129.436, Steps: 200\n",
      "Episode 241, Reward: -362.438, Steps: 200\n",
      "Episode 242, Reward: -130.110, Steps: 200\n",
      "Episode 243, Reward: -132.089, Steps: 200\n",
      "Episode 244, Reward: -372.248, Steps: 200\n",
      "Episode 245, Reward:  -1.890, Steps: 200\n",
      "Episode 246, Reward: -1491.262, Steps: 200\n",
      "Episode 247, Reward: -419.482, Steps: 200\n",
      "Episode 248, Reward: -353.423, Steps: 200\n",
      "Episode 249, Reward: -130.265, Steps: 200\n",
      "Episode 250, Reward: -124.122, Steps: 200\n",
      "Episode 251, Reward: -242.262, Steps: 200\n",
      "Episode 252, Reward: -125.364, Steps: 200\n",
      "Episode 253, Reward: -290.461, Steps: 200\n",
      "Episode 254, Reward: -130.198, Steps: 200\n",
      "Episode 255, Reward: -247.578, Steps: 200\n",
      "Episode 256, Reward: -122.146, Steps: 200\n",
      "Episode 257, Reward: -125.597, Steps: 200\n",
      "Episode 258, Reward: -123.007, Steps: 200\n",
      "Episode 259, Reward: -242.472, Steps: 200\n",
      "Episode 260, Reward: -121.456, Steps: 200\n",
      "Episode 261, Reward: -243.420, Steps: 200\n",
      "Episode 262, Reward: -130.578, Steps: 200\n",
      "Episode 263, Reward:  -0.245, Steps: 200\n",
      "Episode 264, Reward: -121.167, Steps: 200\n",
      "Episode 265, Reward: -252.652, Steps: 200\n",
      "Episode 266, Reward: -239.291, Steps: 200\n",
      "Episode 267, Reward: -121.512, Steps: 200\n",
      "Episode 268, Reward: -124.287, Steps: 200\n",
      "Episode 269, Reward: -126.761, Steps: 200\n",
      "Episode 270, Reward: -347.253, Steps: 200\n",
      "Episode 271, Reward:  -0.263, Steps: 200\n",
      "Episode 272, Reward: -126.389, Steps: 200\n",
      "Episode 273, Reward: -123.546, Steps: 200\n",
      "Episode 274, Reward: -264.359, Steps: 200\n",
      "Episode 275, Reward: -125.529, Steps: 200\n",
      "Episode 276, Reward: -123.148, Steps: 200\n",
      "Episode 277, Reward: -130.162, Steps: 200\n",
      "Episode 278, Reward: -354.098, Steps: 200\n",
      "Episode 279, Reward: -126.689, Steps: 200\n",
      "Episode 280, Reward: -124.345, Steps: 200\n",
      "Episode 281, Reward: -129.254, Steps: 200\n",
      "Episode 282, Reward: -124.102, Steps: 200\n",
      "Episode 283, Reward: -123.706, Steps: 200\n",
      "Episode 284, Reward: -137.025, Steps: 200\n",
      "Episode 285, Reward: -128.622, Steps: 200\n",
      "Episode 286, Reward: -119.373, Steps: 200\n",
      "Episode 287, Reward: -352.184, Steps: 200\n",
      "Episode 288, Reward: -126.837, Steps: 200\n",
      "Episode 289, Reward:  -0.985, Steps: 200\n",
      "Episode 290, Reward: -125.360, Steps: 200\n",
      "Episode 291, Reward: -233.926, Steps: 200\n",
      "Episode 292, Reward: -116.254, Steps: 200\n",
      "Episode 293, Reward:  -0.347, Steps: 200\n",
      "Episode 294, Reward: -130.785, Steps: 200\n",
      "Episode 295, Reward: -114.123, Steps: 200\n",
      "Episode 296, Reward:  -0.146, Steps: 200\n",
      "Episode 297, Reward: -260.552, Steps: 200\n",
      "Episode 298, Reward: -260.842, Steps: 200\n",
      "Episode 299, Reward: -117.666, Steps: 200\n",
      "Episode 300, Reward: -127.302, Steps: 200\n",
      "Episode 301, Reward: -237.059, Steps: 200\n",
      "Episode 302, Reward: -119.057, Steps: 200\n",
      "Episode 303, Reward: -125.996, Steps: 200\n",
      "Episode 304, Reward: -250.479, Steps: 200\n",
      "Episode 305, Reward: -129.464, Steps: 200\n",
      "Episode 306, Reward: -123.630, Steps: 200\n",
      "Episode 307, Reward:  -0.934, Steps: 200\n",
      "Episode 308, Reward: -129.717, Steps: 200\n",
      "Episode 309, Reward: -130.115, Steps: 200\n",
      "Episode 310, Reward: -126.529, Steps: 200\n",
      "Episode 311, Reward: -128.619, Steps: 200\n",
      "Episode 312, Reward: -235.495, Steps: 200\n",
      "Episode 313, Reward: -123.415, Steps: 200\n",
      "Episode 314, Reward: -242.488, Steps: 200\n",
      "Episode 315, Reward:  -0.218, Steps: 200\n",
      "Episode 316, Reward: -126.663, Steps: 200\n",
      "Episode 317, Reward: -125.346, Steps: 200\n",
      "Episode 318, Reward:  -2.933, Steps: 200\n",
      "Episode 319, Reward: -328.674, Steps: 200\n",
      "Episode 320, Reward: -126.349, Steps: 200\n",
      "Episode 321, Reward: -130.285, Steps: 200\n",
      "Episode 322, Reward: -120.292, Steps: 200\n",
      "Episode 323, Reward: -249.436, Steps: 200\n",
      "Episode 324, Reward: -122.070, Steps: 200\n",
      "Episode 325, Reward: -126.279, Steps: 200\n",
      "Episode 326, Reward: -341.925, Steps: 200\n",
      "Episode 327, Reward:  -0.228, Steps: 200\n",
      "Episode 328, Reward:  -1.835, Steps: 200\n",
      "Episode 329, Reward:  -2.822, Steps: 200\n",
      "Episode 330, Reward: -122.089, Steps: 200\n",
      "Episode 331, Reward: -126.014, Steps: 200\n",
      "Episode 332, Reward: -244.245, Steps: 200\n",
      "Episode 333, Reward: -119.092, Steps: 200\n",
      "Episode 334, Reward: -125.859, Steps: 200\n",
      "Episode 335, Reward: -127.701, Steps: 200\n",
      "Episode 336, Reward: -251.051, Steps: 200\n",
      "Episode 337, Reward: -118.908, Steps: 200\n",
      "Episode 338, Reward: -118.284, Steps: 200\n",
      "Episode 339, Reward: -248.473, Steps: 200\n",
      "Episode 340, Reward: -233.091, Steps: 200\n",
      "Episode 341, Reward: -127.189, Steps: 200\n",
      "Episode 342, Reward: -227.121, Steps: 200\n",
      "Episode 343, Reward: -233.134, Steps: 200\n",
      "Episode 344, Reward: -124.791, Steps: 200\n",
      "Episode 345, Reward:  -4.663, Steps: 200\n",
      "Episode 346, Reward: -283.784, Steps: 200\n",
      "Episode 347, Reward: -340.249, Steps: 200\n",
      "Episode 348, Reward: -122.856, Steps: 200\n",
      "Episode 349, Reward: -127.762, Steps: 200\n",
      "Episode 350, Reward:  -0.208, Steps: 200\n",
      "Episode 351, Reward: -262.921, Steps: 200\n",
      "Episode 352, Reward: -127.392, Steps: 200\n",
      "Episode 353, Reward: -255.895, Steps: 200\n",
      "Episode 354, Reward: -128.262, Steps: 200\n",
      "Episode 355, Reward: -243.629, Steps: 200\n",
      "Episode 356, Reward: -319.198, Steps: 200\n",
      "Episode 357, Reward: -126.657, Steps: 200\n",
      "Episode 358, Reward: -124.583, Steps: 200\n",
      "Episode 359, Reward: -253.716, Steps: 200\n",
      "Episode 360, Reward: -217.483, Steps: 200\n",
      "Episode 361, Reward: -127.753, Steps: 200\n",
      "Episode 362, Reward:  -2.659, Steps: 200\n",
      "Episode 363, Reward: -262.305, Steps: 200\n",
      "Episode 364, Reward:  -0.179, Steps: 200\n",
      "Episode 365, Reward: -127.506, Steps: 200\n",
      "Episode 366, Reward: -117.476, Steps: 200\n",
      "Episode 367, Reward:  -0.906, Steps: 200\n",
      "Episode 368, Reward: -123.402, Steps: 200\n",
      "Episode 369, Reward: -379.336, Steps: 200\n",
      "Episode 370, Reward: -269.346, Steps: 200\n",
      "Episode 371, Reward: -114.840, Steps: 200\n",
      "Episode 372, Reward: -364.455, Steps: 200\n",
      "Episode 373, Reward: -124.488, Steps: 200\n",
      "Episode 374, Reward: -250.536, Steps: 200\n",
      "Episode 375, Reward: -244.957, Steps: 200\n",
      "Episode 376, Reward: -124.260, Steps: 200\n",
      "Episode 377, Reward: -363.238, Steps: 200\n",
      "Episode 378, Reward: -128.578, Steps: 200\n",
      "Episode 379, Reward: -238.731, Steps: 200\n",
      "Episode 380, Reward: -238.685, Steps: 200\n",
      "Episode 381, Reward: -301.261, Steps: 200\n",
      "Episode 382, Reward: -242.626, Steps: 200\n",
      "Episode 383, Reward: -122.464, Steps: 200\n",
      "Episode 384, Reward: -121.261, Steps: 200\n",
      "Episode 385, Reward: -131.633, Steps: 200\n",
      "Episode 386, Reward: -114.389, Steps: 200\n",
      "Episode 387, Reward: -388.330, Steps: 200\n",
      "Episode 388, Reward: -116.852, Steps: 200\n",
      "Episode 389, Reward: -122.766, Steps: 200\n",
      "Episode 390, Reward: -242.018, Steps: 200\n",
      "Episode 391, Reward:  -0.338, Steps: 200\n",
      "Episode 392, Reward: -124.927, Steps: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 393, Reward: -234.350, Steps: 200\n",
      "Episode 394, Reward: -116.760, Steps: 200\n",
      "Episode 395, Reward: -130.960, Steps: 200\n",
      "Episode 396, Reward: -351.956, Steps: 200\n",
      "Episode 397, Reward: -243.873, Steps: 200\n",
      "Episode 398, Reward: -114.500, Steps: 200\n",
      "Episode 399, Reward: -126.738, Steps: 200\n",
      "Episode 400, Reward: -127.978, Steps: 200\n",
      "Episode 401, Reward: -123.208, Steps: 200\n",
      "Episode 402, Reward: -128.876, Steps: 200\n",
      "Episode 403, Reward:  -0.055, Steps: 200\n",
      "Episode 404, Reward: -235.491, Steps: 200\n",
      "Episode 405, Reward: -122.603, Steps: 200\n",
      "Episode 406, Reward: -260.107, Steps: 200\n",
      "Episode 407, Reward:  -0.408, Steps: 200\n",
      "Episode 408, Reward: -116.048, Steps: 200\n",
      "Episode 409, Reward: -242.064, Steps: 200\n",
      "Episode 410, Reward: -122.194, Steps: 200\n",
      "Episode 411, Reward: -119.902, Steps: 200\n",
      "Episode 412, Reward: -239.573, Steps: 200\n",
      "Episode 413, Reward: -288.006, Steps: 200\n",
      "Episode 414, Reward: -127.550, Steps: 200\n",
      "Episode 415, Reward: -116.616, Steps: 200\n",
      "Episode 416, Reward: -123.411, Steps: 200\n",
      "Episode 417, Reward: -359.830, Steps: 200\n",
      "Episode 418, Reward: -238.217, Steps: 200\n",
      "Episode 419, Reward: -243.002, Steps: 200\n",
      "Episode 420, Reward: -125.383, Steps: 200\n",
      "Episode 421, Reward: -127.490, Steps: 200\n",
      "Episode 422, Reward: -128.416, Steps: 200\n",
      "Episode 423, Reward: -120.866, Steps: 200\n",
      "Episode 424, Reward: -240.304, Steps: 200\n",
      "Episode 425, Reward:  -0.067, Steps: 200\n",
      "Episode 426, Reward: -126.131, Steps: 200\n",
      "Episode 427, Reward: -117.862, Steps: 200\n",
      "Episode 428, Reward:  -2.874, Steps: 200\n",
      "Episode 429, Reward: -128.254, Steps: 200\n",
      "Episode 430, Reward: -127.403, Steps: 200\n",
      "Episode 431, Reward: -235.079, Steps: 200\n",
      "Episode 432, Reward:  -0.791, Steps: 200\n",
      "Episode 433, Reward: -249.390, Steps: 200\n",
      "Episode 434, Reward: -116.790, Steps: 200\n",
      "Episode 435, Reward: -125.123, Steps: 200\n",
      "Episode 436, Reward: -127.938, Steps: 200\n",
      "Episode 437, Reward: -128.522, Steps: 200\n",
      "Episode 438, Reward: -114.973, Steps: 200\n",
      "Episode 439, Reward: -236.739, Steps: 200\n",
      "Episode 440, Reward: -122.754, Steps: 200\n",
      "Episode 441, Reward: -122.777, Steps: 200\n",
      "Episode 442, Reward: -239.527, Steps: 200\n",
      "Episode 443, Reward: -123.493, Steps: 200\n",
      "Episode 444, Reward: -242.897, Steps: 200\n",
      "Episode 445, Reward: -118.030, Steps: 200\n",
      "Episode 446, Reward: -1412.923, Steps: 200\n",
      "Episode 447, Reward: -119.830, Steps: 200\n",
      "Episode 448, Reward: -238.185, Steps: 200\n",
      "Episode 449, Reward: -122.438, Steps: 200\n",
      "Episode 450, Reward: -250.493, Steps: 200\n",
      "Episode 451, Reward: -123.062, Steps: 200\n",
      "Episode 452, Reward: -519.671, Steps: 200\n",
      "Episode 453, Reward:  -1.740, Steps: 200\n",
      "Episode 454, Reward: -119.672, Steps: 200\n",
      "Episode 455, Reward: -120.216, Steps: 200\n",
      "Episode 456, Reward: -399.805, Steps: 200\n",
      "Episode 457, Reward: -237.422, Steps: 200\n",
      "Episode 458, Reward: -123.459, Steps: 200\n",
      "Episode 459, Reward:  -1.553, Steps: 200\n",
      "Episode 460, Reward: -117.951, Steps: 200\n",
      "Episode 461, Reward: -514.953, Steps: 200\n",
      "Episode 462, Reward:  -1.755, Steps: 200\n",
      "Episode 463, Reward: -369.289, Steps: 200\n",
      "Episode 464, Reward: -256.291, Steps: 200\n",
      "Episode 465, Reward: -259.362, Steps: 200\n",
      "Episode 466, Reward: -129.183, Steps: 200\n",
      "Episode 467, Reward:  -1.001, Steps: 200\n",
      "Episode 468, Reward: -267.918, Steps: 200\n",
      "Episode 469, Reward: -910.807, Steps: 200\n",
      "Episode 470, Reward: -1117.752, Steps: 200\n",
      "Episode 471, Reward: -114.853, Steps: 200\n",
      "Episode 472, Reward: -1040.559, Steps: 200\n",
      "Episode 473, Reward: -114.597, Steps: 200\n",
      "Episode 474, Reward: -115.115, Steps: 200\n",
      "Episode 475, Reward:  -1.937, Steps: 200\n",
      "Episode 476, Reward: -255.636, Steps: 200\n",
      "Episode 477, Reward: -122.316, Steps: 200\n",
      "Episode 478, Reward: -850.565, Steps: 200\n",
      "Episode 479, Reward: -241.799, Steps: 200\n",
      "Episode 480, Reward: -115.524, Steps: 200\n",
      "Episode 481, Reward: -126.653, Steps: 200\n",
      "Episode 482, Reward: -899.849, Steps: 200\n",
      "Episode 483, Reward: -238.512, Steps: 200\n",
      "Episode 484, Reward: -241.992, Steps: 200\n",
      "Episode 485, Reward: -120.009, Steps: 200\n",
      "Episode 486, Reward: -122.200, Steps: 200\n",
      "Episode 487, Reward: -118.474, Steps: 200\n",
      "Episode 488, Reward: -225.507, Steps: 200\n",
      "Episode 489, Reward: -925.556, Steps: 200\n",
      "Episode 490, Reward: -122.298, Steps: 200\n",
      "Episode 491, Reward: -237.566, Steps: 200\n",
      "Episode 492, Reward: -123.691, Steps: 200\n",
      "Episode 493, Reward: -120.126, Steps: 200\n",
      "Episode 494, Reward: -281.309, Steps: 200\n",
      "Episode 495, Reward: -122.560, Steps: 200\n",
      "Episode 496, Reward: -125.422, Steps: 200\n",
      "Episode 497, Reward: -124.346, Steps: 200\n",
      "Episode 498, Reward: -1033.300, Steps: 200\n",
      "Episode 499, Reward:  -1.448, Steps: 200\n",
      "Episode 500, Reward: -114.814, Steps: 200\n",
      "Episode 501, Reward: -875.068, Steps: 200\n",
      "Episode 502, Reward: -231.755, Steps: 200\n",
      "Episode 503, Reward: -229.144, Steps: 200\n",
      "Episode 504, Reward: -510.350, Steps: 200\n",
      "Episode 505, Reward: -902.342, Steps: 200\n",
      "Episode 506, Reward: -121.805, Steps: 200\n",
      "Episode 507, Reward: -123.714, Steps: 200\n",
      "Episode 508, Reward: -1120.476, Steps: 200\n",
      "Episode 509, Reward: -122.563, Steps: 200\n",
      "Episode 510, Reward: -122.107, Steps: 200\n",
      "Episode 511, Reward: -513.770, Steps: 200\n",
      "Episode 512, Reward: -233.358, Steps: 200\n",
      "Episode 513, Reward: -228.186, Steps: 200\n",
      "Episode 514, Reward: -123.268, Steps: 200\n",
      "Episode 515, Reward: -254.161, Steps: 200\n",
      "Episode 516, Reward:  -2.480, Steps: 200\n",
      "Episode 517, Reward: -123.584, Steps: 200\n",
      "Episode 518, Reward: -229.672, Steps: 200\n",
      "Episode 519, Reward: -1029.934, Steps: 200\n",
      "Episode 520, Reward: -124.067, Steps: 200\n",
      "Episode 521, Reward: -120.045, Steps: 200\n",
      "Episode 522, Reward:  -1.388, Steps: 200\n",
      "Episode 523, Reward: -234.454, Steps: 200\n",
      "Episode 524, Reward:  -3.168, Steps: 200\n",
      "Episode 525, Reward: -117.885, Steps: 200\n",
      "Episode 526, Reward: -116.174, Steps: 200\n",
      "Episode 527, Reward: -1152.721, Steps: 200\n",
      "Episode 528, Reward: -1115.843, Steps: 200\n",
      "Episode 529, Reward: -229.590, Steps: 200\n",
      "Episode 530, Reward: -338.004, Steps: 200\n",
      "Episode 531, Reward: -122.458, Steps: 200\n",
      "Episode 532, Reward: -222.271, Steps: 200\n",
      "Episode 533, Reward: -231.024, Steps: 200\n",
      "Episode 534, Reward: -120.124, Steps: 200\n",
      "Episode 535, Reward: -307.586, Steps: 200\n",
      "Episode 536, Reward: -1651.748, Steps: 200\n",
      "Episode 537, Reward: -122.171, Steps: 200\n",
      "Episode 538, Reward: -123.051, Steps: 200\n",
      "Episode 539, Reward: -123.740, Steps: 200\n",
      "Episode 540, Reward: -119.878, Steps: 200\n",
      "Episode 541, Reward: -229.714, Steps: 200\n",
      "Episode 542, Reward: -236.536, Steps: 200\n",
      "Episode 543, Reward: -238.051, Steps: 200\n",
      "Episode 544, Reward: -115.776, Steps: 200\n",
      "Episode 545, Reward: -120.118, Steps: 200\n",
      "Episode 546, Reward: -1654.326, Steps: 200\n",
      "Episode 547, Reward: -120.661, Steps: 200\n",
      "Episode 548, Reward: -118.551, Steps: 200\n",
      "Episode 549, Reward:  -1.861, Steps: 200\n",
      "Episode 550, Reward: -1658.306, Steps: 200\n",
      "Episode 551, Reward: -323.582, Steps: 200\n",
      "Episode 552, Reward:  -3.451, Steps: 200\n",
      "Episode 553, Reward: -117.786, Steps: 200\n",
      "Episode 554, Reward: -239.030, Steps: 200\n",
      "Episode 555, Reward: -121.060, Steps: 200\n",
      "Episode 556, Reward: -122.683, Steps: 200\n",
      "Episode 557, Reward: -235.154, Steps: 200\n",
      "Episode 558, Reward: -311.011, Steps: 200\n",
      "Episode 559, Reward:  -1.606, Steps: 200\n",
      "Episode 560, Reward: -340.845, Steps: 200\n",
      "Episode 561, Reward:  -1.326, Steps: 200\n",
      "Episode 562, Reward: -231.307, Steps: 200\n",
      "Episode 563, Reward: -348.799, Steps: 200\n",
      "Episode 564, Reward: -117.198, Steps: 200\n",
      "Episode 565, Reward:  -1.516, Steps: 200\n",
      "Episode 566, Reward: -128.954, Steps: 200\n",
      "Episode 567, Reward: -124.155, Steps: 200\n",
      "Episode 568, Reward: -922.034, Steps: 200\n",
      "Episode 569, Reward: -1654.863, Steps: 200\n",
      "Episode 570, Reward: -325.860, Steps: 200\n",
      "Episode 571, Reward: -331.374, Steps: 200\n",
      "Episode 572, Reward:  -1.947, Steps: 200\n",
      "Episode 573, Reward: -250.022, Steps: 200\n",
      "Episode 574, Reward:  -4.490, Steps: 200\n",
      "Episode 575, Reward: -119.007, Steps: 200\n",
      "Episode 576, Reward: -125.724, Steps: 200\n",
      "Episode 577, Reward: -339.106, Steps: 200\n",
      "Episode 578, Reward: -517.036, Steps: 200\n",
      "Episode 579, Reward: -124.475, Steps: 200\n",
      "Episode 580, Reward: -226.210, Steps: 200\n",
      "Episode 581, Reward: -229.638, Steps: 200\n",
      "Episode 582, Reward: -310.906, Steps: 200\n",
      "Episode 583, Reward: -235.352, Steps: 200\n",
      "Episode 584, Reward: -124.395, Steps: 200\n",
      "Episode 585, Reward:  -3.758, Steps: 200\n",
      "Episode 586, Reward: -644.016, Steps: 200\n",
      "Episode 587, Reward:  -6.300, Steps: 200\n",
      "Episode 588, Reward: -338.324, Steps: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 589, Reward:  -4.596, Steps: 200\n",
      "Episode 590, Reward: -358.328, Steps: 200\n",
      "Episode 591, Reward: -123.349, Steps: 200\n",
      "Episode 592, Reward:  -5.402, Steps: 200\n",
      "Episode 593, Reward: -291.838, Steps: 200\n",
      "Episode 594, Reward: -124.081, Steps: 200\n",
      "Episode 595, Reward: -253.667, Steps: 200\n",
      "Episode 596, Reward: -132.024, Steps: 200\n",
      "Episode 597, Reward: -259.152, Steps: 200\n",
      "Episode 598, Reward: -363.536, Steps: 200\n",
      "Episode 599, Reward: -132.812, Steps: 200\n",
      "Episode 600, Reward: -11.828, Steps: 200\n",
      "Episode 601, Reward: -132.003, Steps: 200\n",
      "Episode 602, Reward: -1272.291, Steps: 200\n",
      "Episode 603, Reward: -1065.860, Steps: 200\n",
      "Episode 604, Reward: -1083.277, Steps: 200\n",
      "Episode 605, Reward: -1053.255, Steps: 200\n",
      "Episode 606, Reward: -1121.589, Steps: 200\n",
      "Episode 607, Reward: -915.979, Steps: 200\n",
      "Episode 608, Reward: -1017.573, Steps: 200\n",
      "Episode 609, Reward: -270.929, Steps: 200\n",
      "Episode 610, Reward: -252.228, Steps: 200\n",
      "Episode 611, Reward: -10.750, Steps: 200\n",
      "Episode 612, Reward: -133.791, Steps: 200\n",
      "Episode 613, Reward: -238.674, Steps: 200\n",
      "Episode 614, Reward:  -6.194, Steps: 200\n",
      "Episode 615, Reward: -127.586, Steps: 200\n",
      "Episode 616, Reward: -117.789, Steps: 200\n",
      "Episode 617, Reward: -122.390, Steps: 200\n",
      "Episode 618, Reward: -349.753, Steps: 200\n",
      "Episode 619, Reward: -232.684, Steps: 200\n",
      "Episode 620, Reward: -251.198, Steps: 200\n",
      "Episode 621, Reward: -129.520, Steps: 200\n",
      "Episode 622, Reward: -121.459, Steps: 200\n",
      "Episode 623, Reward: -122.163, Steps: 200\n",
      "Episode 624, Reward: -367.696, Steps: 200\n",
      "Episode 625, Reward: -127.777, Steps: 200\n",
      "Episode 626, Reward:  -0.225, Steps: 200\n",
      "Episode 627, Reward: -367.349, Steps: 200\n",
      "Episode 628, Reward: -122.724, Steps: 200\n",
      "Episode 629, Reward: -130.794, Steps: 200\n",
      "Episode 630, Reward:  -0.362, Steps: 200\n",
      "Episode 631, Reward: -366.778, Steps: 200\n",
      "Episode 632, Reward:  -1.342, Steps: 200\n",
      "Episode 633, Reward:  -0.229, Steps: 200\n",
      "Episode 634, Reward:  -3.790, Steps: 200\n",
      "Episode 635, Reward: -120.137, Steps: 200\n",
      "Episode 636, Reward: -127.483, Steps: 200\n",
      "Episode 637, Reward: -121.453, Steps: 200\n",
      "Episode 638, Reward: -130.215, Steps: 200\n",
      "Episode 639, Reward: -408.461, Steps: 200\n",
      "Episode 640, Reward: -121.448, Steps: 200\n",
      "Episode 641, Reward: -267.046, Steps: 200\n",
      "Episode 642, Reward: -491.579, Steps: 200\n",
      "Episode 643, Reward: -129.982, Steps: 200\n",
      "Episode 644, Reward: -123.588, Steps: 200\n",
      "Episode 645, Reward: -127.218, Steps: 200\n",
      "Episode 646, Reward: -127.105, Steps: 200\n",
      "Episode 647, Reward: -129.806, Steps: 200\n",
      "Episode 648, Reward: -122.114, Steps: 200\n",
      "Episode 649, Reward:  -0.607, Steps: 200\n",
      "Episode 650, Reward: -248.245, Steps: 200\n",
      "Episode 651, Reward: -366.125, Steps: 200\n",
      "Episode 652, Reward: -420.593, Steps: 200\n",
      "Episode 653, Reward: -127.270, Steps: 200\n",
      "Episode 654, Reward: -129.353, Steps: 200\n",
      "Episode 655, Reward:  -0.100, Steps: 200\n",
      "Episode 656, Reward: -254.352, Steps: 200\n",
      "Episode 657, Reward: -495.876, Steps: 200\n",
      "Episode 658, Reward: -127.970, Steps: 200\n",
      "Episode 659, Reward:  -0.153, Steps: 200\n",
      "Episode 660, Reward: -250.536, Steps: 200\n",
      "Episode 661, Reward: -133.873, Steps: 200\n",
      "Episode 662, Reward: -249.329, Steps: 200\n",
      "Episode 663, Reward: -131.339, Steps: 200\n",
      "Episode 664, Reward: -251.886, Steps: 200\n",
      "Episode 665, Reward: -128.781, Steps: 200\n",
      "Episode 666, Reward: -131.952, Steps: 200\n",
      "Episode 667, Reward: -363.190, Steps: 200\n",
      "Episode 668, Reward:  -0.613, Steps: 200\n",
      "Episode 669, Reward:  -6.240, Steps: 200\n",
      "Episode 670, Reward: -262.098, Steps: 200\n",
      "Episode 671, Reward: -127.232, Steps: 200\n",
      "Episode 672, Reward: -134.423, Steps: 200\n",
      "Episode 673, Reward: -126.802, Steps: 200\n",
      "Episode 674, Reward: -129.808, Steps: 200\n",
      "Episode 675, Reward: -123.527, Steps: 200\n",
      "Episode 676, Reward: -269.339, Steps: 200\n",
      "Episode 677, Reward:  -2.718, Steps: 200\n",
      "Episode 678, Reward: -129.418, Steps: 200\n",
      "Episode 679, Reward: -344.980, Steps: 200\n",
      "Episode 680, Reward: -134.650, Steps: 200\n",
      "Episode 681, Reward: -130.643, Steps: 200\n",
      "Episode 682, Reward: -119.753, Steps: 200\n",
      "Episode 683, Reward: -121.171, Steps: 200\n",
      "Episode 684, Reward: -126.946, Steps: 200\n",
      "Episode 685, Reward:  -0.010, Steps: 200\n",
      "Episode 686, Reward:  -0.225, Steps: 200\n",
      "Episode 687, Reward:  -1.263, Steps: 200\n",
      "Episode 688, Reward: -363.144, Steps: 200\n",
      "Episode 689, Reward: -245.218, Steps: 200\n",
      "Episode 690, Reward: -348.003, Steps: 200\n",
      "Episode 691, Reward: -257.847, Steps: 200\n",
      "Episode 692, Reward:  -1.026, Steps: 200\n",
      "Episode 693, Reward: -238.099, Steps: 200\n",
      "Episode 694, Reward: -245.189, Steps: 200\n",
      "Episode 695, Reward: -279.944, Steps: 200\n",
      "Episode 696, Reward:  -1.303, Steps: 200\n",
      "Episode 697, Reward:  -0.625, Steps: 200\n",
      "Episode 698, Reward: -388.192, Steps: 200\n",
      "Episode 699, Reward: -332.540, Steps: 200\n",
      "Episode 700, Reward: -237.977, Steps: 200\n",
      "Episode 701, Reward: -128.817, Steps: 200\n",
      "Episode 702, Reward:  -0.829, Steps: 200\n",
      "Episode 703, Reward: -128.994, Steps: 200\n",
      "Episode 704, Reward: -363.937, Steps: 200\n",
      "Episode 705, Reward: -125.043, Steps: 200\n",
      "Episode 706, Reward: -401.814, Steps: 200\n",
      "Episode 707, Reward: -261.423, Steps: 200\n",
      "Episode 708, Reward: -236.917, Steps: 200\n",
      "Episode 709, Reward: -123.319, Steps: 200\n",
      "Episode 710, Reward: -127.978, Steps: 200\n",
      "Episode 711, Reward: -239.025, Steps: 200\n",
      "Episode 712, Reward: -403.042, Steps: 200\n",
      "Episode 713, Reward:  -0.570, Steps: 200\n",
      "Episode 714, Reward: -118.113, Steps: 200\n",
      "Episode 715, Reward: -236.465, Steps: 200\n",
      "Episode 716, Reward: -128.939, Steps: 200\n",
      "Episode 717, Reward: -126.102, Steps: 200\n",
      "Episode 718, Reward:  -0.291, Steps: 200\n",
      "Episode 719, Reward: -239.574, Steps: 200\n",
      "Episode 720, Reward: -113.908, Steps: 200\n",
      "Episode 721, Reward: -121.549, Steps: 200\n",
      "Episode 722, Reward: -117.220, Steps: 200\n",
      "Episode 723, Reward: -124.900, Steps: 200\n",
      "Episode 724, Reward: -236.799, Steps: 200\n",
      "Episode 725, Reward: -240.896, Steps: 200\n",
      "Episode 726, Reward: -115.672, Steps: 200\n",
      "Episode 727, Reward: -122.967, Steps: 200\n",
      "Episode 728, Reward: -221.981, Steps: 200\n",
      "Episode 729, Reward: -113.650, Steps: 200\n",
      "Episode 730, Reward: -364.135, Steps: 200\n",
      "Episode 731, Reward: -124.217, Steps: 200\n",
      "Episode 732, Reward: -114.603, Steps: 200\n",
      "Episode 733, Reward: -124.553, Steps: 200\n",
      "Episode 734, Reward:  -1.993, Steps: 200\n",
      "Episode 735, Reward: -121.907, Steps: 200\n",
      "Episode 736, Reward: -119.945, Steps: 200\n",
      "Episode 737, Reward: -120.808, Steps: 200\n",
      "Episode 738, Reward: -124.509, Steps: 200\n",
      "Episode 739, Reward: -123.151, Steps: 200\n",
      "Episode 740, Reward: -124.490, Steps: 200\n",
      "Episode 741, Reward: -119.698, Steps: 200\n",
      "Episode 742, Reward: -232.074, Steps: 200\n",
      "Episode 743, Reward: -115.960, Steps: 200\n",
      "Episode 744, Reward: -116.763, Steps: 200\n",
      "Episode 745, Reward: -239.934, Steps: 200\n",
      "Episode 746, Reward: -123.692, Steps: 200\n",
      "Episode 747, Reward: -230.496, Steps: 200\n",
      "Episode 748, Reward: -233.602, Steps: 200\n",
      "Episode 749, Reward: -125.033, Steps: 200\n",
      "Episode 750, Reward:  -1.424, Steps: 200\n",
      "Episode 751, Reward: -124.351, Steps: 200\n",
      "Episode 752, Reward: -237.193, Steps: 200\n",
      "Episode 753, Reward:  -0.381, Steps: 200\n",
      "Episode 754, Reward:  -0.530, Steps: 200\n",
      "Episode 755, Reward: -233.484, Steps: 200\n",
      "Episode 756, Reward: -122.431, Steps: 200\n",
      "Episode 757, Reward:  -1.766, Steps: 200\n",
      "Episode 758, Reward: -226.755, Steps: 200\n",
      "Episode 759, Reward: -1496.667, Steps: 200\n",
      "Episode 760, Reward: -126.017, Steps: 200\n",
      "Episode 761, Reward: -127.166, Steps: 200\n",
      "Episode 762, Reward:  -0.449, Steps: 200\n",
      "Episode 763, Reward:  -0.329, Steps: 200\n",
      "Episode 764, Reward:  -1.115, Steps: 200\n",
      "Episode 765, Reward: -249.951, Steps: 200\n",
      "Episode 766, Reward: -387.238, Steps: 200\n",
      "Episode 767, Reward: -234.902, Steps: 200\n",
      "Episode 768, Reward: -118.242, Steps: 200\n",
      "Episode 769, Reward: -255.451, Steps: 200\n",
      "Episode 770, Reward: -119.923, Steps: 200\n",
      "Episode 771, Reward: -231.820, Steps: 200\n",
      "Episode 772, Reward: -246.267, Steps: 200\n",
      "Episode 773, Reward:  -0.160, Steps: 200\n",
      "Episode 774, Reward: -235.867, Steps: 200\n",
      "Episode 775, Reward: -245.990, Steps: 200\n",
      "Episode 776, Reward: -127.776, Steps: 200\n",
      "Episode 777, Reward: -127.471, Steps: 200\n",
      "Episode 778, Reward: -375.090, Steps: 200\n",
      "Episode 779, Reward: -123.686, Steps: 200\n",
      "Episode 780, Reward: -127.612, Steps: 200\n",
      "Episode 781, Reward: -238.545, Steps: 200\n",
      "Episode 782, Reward: -256.087, Steps: 200\n",
      "Episode 783, Reward: -125.376, Steps: 200\n",
      "Episode 784, Reward: -242.466, Steps: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 785, Reward: -128.007, Steps: 200\n",
      "Episode 786, Reward: -1503.783, Steps: 200\n",
      "Episode 787, Reward: -124.022, Steps: 200\n",
      "Episode 788, Reward: -494.150, Steps: 200\n",
      "Episode 789, Reward: -224.403, Steps: 200\n",
      "Episode 790, Reward:  -1.561, Steps: 200\n",
      "Episode 791, Reward: -128.308, Steps: 200\n",
      "Episode 792, Reward: -225.665, Steps: 200\n",
      "Episode 793, Reward: -1497.410, Steps: 200\n",
      "Episode 794, Reward: -237.520, Steps: 200\n",
      "Episode 795, Reward: -238.194, Steps: 200\n",
      "Episode 796, Reward: -227.664, Steps: 200\n",
      "Episode 797, Reward: -243.171, Steps: 200\n",
      "Episode 798, Reward: -230.200, Steps: 200\n",
      "Episode 799, Reward: -118.392, Steps: 200\n",
      "Episode 800, Reward: -246.885, Steps: 200\n",
      "Episode 801, Reward: -118.754, Steps: 200\n",
      "Episode 802, Reward: -235.122, Steps: 200\n",
      "Episode 803, Reward:  -0.013, Steps: 200\n",
      "Episode 804, Reward: -508.942, Steps: 200\n",
      "Episode 805, Reward: -253.074, Steps: 200\n",
      "Episode 806, Reward: -252.168, Steps: 200\n",
      "Episode 807, Reward: -240.927, Steps: 200\n",
      "Episode 808, Reward: -126.246, Steps: 200\n",
      "Episode 809, Reward: -255.533, Steps: 200\n",
      "Episode 810, Reward: -237.050, Steps: 200\n",
      "Episode 811, Reward: -238.831, Steps: 200\n",
      "Episode 812, Reward: -1496.348, Steps: 200\n",
      "Episode 813, Reward: -240.779, Steps: 200\n",
      "Episode 814, Reward: -254.211, Steps: 200\n",
      "Episode 815, Reward: -118.222, Steps: 200\n",
      "Episode 816, Reward: -1490.879, Steps: 200\n",
      "Episode 817, Reward: -256.432, Steps: 200\n",
      "Episode 818, Reward: -126.582, Steps: 200\n",
      "Episode 819, Reward: -252.735, Steps: 200\n",
      "Episode 820, Reward: -430.196, Steps: 200\n",
      "Episode 821, Reward:  -0.543, Steps: 200\n",
      "Episode 822, Reward: -127.323, Steps: 200\n",
      "Episode 823, Reward: -118.782, Steps: 200\n",
      "Episode 824, Reward: -128.499, Steps: 200\n",
      "Episode 825, Reward: -254.358, Steps: 200\n",
      "Episode 826, Reward: -115.545, Steps: 200\n",
      "Episode 827, Reward: -253.651, Steps: 200\n",
      "Episode 828, Reward:  -1.551, Steps: 200\n",
      "Episode 829, Reward: -504.187, Steps: 200\n",
      "Episode 830, Reward: -649.639, Steps: 200\n",
      "Episode 831, Reward: -127.812, Steps: 200\n",
      "Episode 832, Reward: -477.494, Steps: 200\n",
      "Episode 833, Reward: -246.424, Steps: 200\n",
      "Episode 834, Reward: -235.915, Steps: 200\n",
      "Episode 835, Reward: -129.208, Steps: 200\n",
      "Episode 836, Reward:  -0.889, Steps: 200\n",
      "Episode 837, Reward: -244.942, Steps: 200\n",
      "Episode 838, Reward: -240.538, Steps: 200\n",
      "Episode 839, Reward: -394.939, Steps: 200\n",
      "Episode 840, Reward: -368.974, Steps: 200\n",
      "Episode 841, Reward: -373.764, Steps: 200\n",
      "Episode 842, Reward: -244.781, Steps: 200\n",
      "Episode 843, Reward: -353.008, Steps: 200\n",
      "Episode 844, Reward: -255.224, Steps: 200\n",
      "Episode 845, Reward: -240.191, Steps: 200\n",
      "Episode 846, Reward:  -1.421, Steps: 200\n",
      "Episode 847, Reward: -229.654, Steps: 200\n",
      "Episode 848, Reward: -251.018, Steps: 200\n",
      "Episode 849, Reward: -247.860, Steps: 200\n",
      "Episode 850, Reward: -247.849, Steps: 200\n",
      "Episode 851, Reward:  -0.076, Steps: 200\n",
      "Episode 852, Reward: -454.353, Steps: 200\n",
      "Episode 853, Reward: -247.231, Steps: 200\n",
      "Episode 854, Reward: -367.163, Steps: 200\n",
      "Episode 855, Reward: -570.332, Steps: 200\n",
      "Episode 856, Reward: -242.840, Steps: 200\n",
      "Episode 857, Reward: -349.514, Steps: 200\n",
      "Episode 858, Reward: -358.902, Steps: 200\n",
      "Episode 859, Reward: -250.556, Steps: 200\n",
      "Episode 860, Reward: -118.948, Steps: 200\n",
      "Episode 861, Reward:  -0.086, Steps: 200\n",
      "Episode 862, Reward: -239.151, Steps: 200\n",
      "Episode 863, Reward: -126.674, Steps: 200\n",
      "Episode 864, Reward: -115.647, Steps: 200\n",
      "Episode 865, Reward: -124.387, Steps: 200\n",
      "Episode 866, Reward: -122.116, Steps: 200\n",
      "Episode 867, Reward: -125.659, Steps: 200\n",
      "Episode 868, Reward: -491.798, Steps: 200\n",
      "Episode 869, Reward: -224.430, Steps: 200\n",
      "Episode 870, Reward: -228.650, Steps: 200\n",
      "Episode 871, Reward: -116.486, Steps: 200\n",
      "Episode 872, Reward: -118.873, Steps: 200\n",
      "Episode 873, Reward:  -0.117, Steps: 200\n",
      "Episode 874, Reward: -119.567, Steps: 200\n",
      "Episode 875, Reward: -248.046, Steps: 200\n",
      "Episode 876, Reward: -123.335, Steps: 200\n",
      "Episode 877, Reward: -248.919, Steps: 200\n",
      "Episode 878, Reward:  -0.034, Steps: 200\n",
      "Episode 879, Reward:  -0.294, Steps: 200\n",
      "Episode 880, Reward: -125.845, Steps: 200\n",
      "Episode 881, Reward: -1493.218, Steps: 200\n",
      "Episode 882, Reward: -119.391, Steps: 200\n",
      "Episode 883, Reward: -113.773, Steps: 200\n",
      "Episode 884, Reward: -447.710, Steps: 200\n",
      "Episode 885, Reward: -116.984, Steps: 200\n",
      "Episode 886, Reward: -461.880, Steps: 200\n",
      "Episode 887, Reward: -121.138, Steps: 200\n",
      "Episode 888, Reward: -356.576, Steps: 200\n",
      "Episode 889, Reward: -227.531, Steps: 200\n",
      "Episode 890, Reward: -248.412, Steps: 200\n",
      "Episode 891, Reward: -242.159, Steps: 200\n",
      "Episode 892, Reward: -225.065, Steps: 200\n",
      "Episode 893, Reward: -127.013, Steps: 200\n",
      "Episode 894, Reward:  -0.488, Steps: 200\n",
      "Episode 895, Reward: -118.561, Steps: 200\n",
      "Episode 896, Reward: -116.104, Steps: 200\n",
      "Episode 897, Reward: -231.862, Steps: 200\n",
      "Episode 898, Reward: -118.383, Steps: 200\n",
      "Episode 899, Reward: -537.012, Steps: 200\n",
      "Episode 900, Reward: -131.915, Steps: 200\n",
      "Episode 901, Reward:  -0.129, Steps: 200\n",
      "Episode 902, Reward: -223.169, Steps: 200\n",
      "Episode 903, Reward: -234.122, Steps: 200\n",
      "Episode 904, Reward: -1490.988, Steps: 200\n",
      "Episode 905, Reward:  -0.844, Steps: 200\n",
      "Episode 906, Reward: -249.201, Steps: 200\n",
      "Episode 907, Reward: -124.445, Steps: 200\n",
      "Episode 908, Reward: -126.613, Steps: 200\n",
      "Episode 909, Reward: -119.616, Steps: 200\n",
      "Episode 910, Reward: -390.839, Steps: 200\n",
      "Episode 911, Reward: -123.064, Steps: 200\n",
      "Episode 912, Reward: -437.930, Steps: 200\n",
      "Episode 913, Reward: -237.182, Steps: 200\n",
      "Episode 914, Reward: -236.525, Steps: 200\n",
      "Episode 915, Reward: -117.812, Steps: 200\n",
      "Episode 916, Reward: -335.362, Steps: 200\n",
      "Episode 917, Reward: -389.776, Steps: 200\n",
      "Episode 918, Reward:  -0.917, Steps: 200\n",
      "Episode 919, Reward: -117.827, Steps: 200\n",
      "Episode 920, Reward: -230.986, Steps: 200\n",
      "Episode 921, Reward: -229.059, Steps: 200\n",
      "Episode 922, Reward: -118.726, Steps: 200\n",
      "Episode 923, Reward: -300.538, Steps: 200\n",
      "Episode 924, Reward: -113.956, Steps: 200\n",
      "Episode 925, Reward: -467.285, Steps: 200\n",
      "Episode 926, Reward: -116.525, Steps: 200\n",
      "Episode 927, Reward: -237.438, Steps: 200\n",
      "Episode 928, Reward: -118.444, Steps: 200\n",
      "Episode 929, Reward: -117.189, Steps: 200\n",
      "Episode 930, Reward:  -0.244, Steps: 200\n",
      "Episode 931, Reward: -524.148, Steps: 200\n",
      "Episode 932, Reward:  -0.492, Steps: 200\n",
      "Episode 933, Reward: -359.159, Steps: 200\n",
      "Episode 934, Reward: -242.289, Steps: 200\n",
      "Episode 935, Reward: -118.114, Steps: 200\n",
      "Episode 936, Reward: -228.527, Steps: 200\n",
      "Episode 937, Reward: -125.815, Steps: 200\n",
      "Episode 938, Reward:  -0.808, Steps: 200\n",
      "Episode 939, Reward: -118.729, Steps: 200\n",
      "Episode 940, Reward: -225.058, Steps: 200\n",
      "Episode 941, Reward: -123.897, Steps: 200\n",
      "Episode 942, Reward: -125.736, Steps: 200\n",
      "Episode 943, Reward: -119.964, Steps: 200\n",
      "Episode 944, Reward: -119.889, Steps: 200\n",
      "Episode 945, Reward: -117.132, Steps: 200\n",
      "Episode 946, Reward: -120.684, Steps: 200\n",
      "Episode 947, Reward: -126.240, Steps: 200\n",
      "Episode 948, Reward:  -0.880, Steps: 200\n",
      "Episode 949, Reward: -123.943, Steps: 200\n",
      "Episode 950, Reward: -130.592, Steps: 200\n",
      "Episode 951, Reward: -225.405, Steps: 200\n",
      "Episode 952, Reward: -244.563, Steps: 200\n",
      "Episode 953, Reward: -237.123, Steps: 200\n",
      "Episode 954, Reward: -119.389, Steps: 200\n",
      "Episode 955, Reward:  -2.221, Steps: 200\n",
      "Episode 956, Reward: -227.128, Steps: 200\n",
      "Episode 957, Reward: -260.978, Steps: 200\n",
      "Episode 958, Reward: -127.912, Steps: 200\n",
      "Episode 959, Reward: -230.735, Steps: 200\n",
      "Episode 960, Reward:  -0.021, Steps: 200\n",
      "Episode 961, Reward: -116.338, Steps: 200\n",
      "Episode 962, Reward: -242.460, Steps: 200\n",
      "Episode 963, Reward: -239.657, Steps: 200\n",
      "Episode 964, Reward: -268.392, Steps: 200\n",
      "Episode 965, Reward: -348.326, Steps: 200\n",
      "Episode 966, Reward:  -0.531, Steps: 200\n",
      "Episode 967, Reward: -245.091, Steps: 200\n",
      "Episode 968, Reward:  -0.692, Steps: 200\n",
      "Episode 969, Reward: -236.981, Steps: 200\n",
      "Episode 970, Reward: -234.810, Steps: 200\n",
      "Episode 971, Reward:  -0.577, Steps: 200\n",
      "Episode 972, Reward: -224.432, Steps: 200\n",
      "Episode 973, Reward: -341.130, Steps: 200\n",
      "Episode 974, Reward: -417.787, Steps: 200\n",
      "Episode 975, Reward: -229.092, Steps: 200\n",
      "Episode 976, Reward: -116.516, Steps: 200\n",
      "Episode 977, Reward: -233.153, Steps: 200\n",
      "Episode 978, Reward: -270.533, Steps: 200\n",
      "Episode 979, Reward:  -0.586, Steps: 200\n",
      "Episode 980, Reward: -246.473, Steps: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 981, Reward: -1491.419, Steps: 200\n",
      "Episode 982, Reward: -391.743, Steps: 200\n",
      "Episode 983, Reward: -241.576, Steps: 200\n",
      "Episode 984, Reward: -234.624, Steps: 200\n",
      "Episode 985, Reward: -114.078, Steps: 200\n",
      "Episode 986, Reward: -244.728, Steps: 200\n",
      "Episode 987, Reward: -244.967, Steps: 200\n",
      "Episode 988, Reward: -121.275, Steps: 200\n",
      "Episode 989, Reward: -233.381, Steps: 200\n",
      "Episode 990, Reward: -119.542, Steps: 200\n",
      "Episode 991, Reward: -231.355, Steps: 200\n",
      "Episode 992, Reward: -681.466, Steps: 200\n",
      "Episode 993, Reward: -231.554, Steps: 200\n",
      "Episode 994, Reward: -340.893, Steps: 200\n",
      "Episode 995, Reward: -379.802, Steps: 200\n",
      "Episode 996, Reward: -243.913, Steps: 200\n",
      "Episode 997, Reward: -119.213, Steps: 200\n",
      "Episode 998, Reward:  -0.141, Steps: 200\n",
      "Episode 999, Reward: -119.709, Steps: 200\n"
     ]
    }
   ],
   "source": [
    "# initialize session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "env = wrappers.Monitor(env, '/home/tom/Desktop/work/reinforcement_learning/pendulum-v0')\n",
    "\n",
    "# set seeds to 0\n",
    "env.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "agent = Agent(env)\n",
    "\n",
    "total_steps = 0\n",
    "for ep in range(num_episodes):\n",
    "\n",
    "    total_reward = 0\n",
    "    steps_in_ep = 0\n",
    "\n",
    "    # Initial state\n",
    "    s_t = env.reset()\n",
    "    if ep % 10 == 0: env.render()\n",
    "\n",
    "    for t in range(max_steps_ep):\n",
    "        a_t = agent.act(s_t.reshape(1,3), stochastic=False)\n",
    "\n",
    "        # take step\n",
    "        s_t_plus_1, r_t, done, _info = env.step(a_t)\n",
    "        if ep % 10 == 0: env.render()\n",
    "        total_reward += r_t\n",
    "\n",
    "        agent.replay_memory.store(s_t.reshape(1,3), a_t, r_t, s_t_plus_1, 0.0 if done else 1.0)\n",
    "        \n",
    "        # update network weights to fit a minibatch of experience\n",
    "        if total_steps % train_every == 0 and len(agent.replay_memory.buffer) >= minibatch_size:\n",
    "            agent.train()\n",
    "            \n",
    "        s_t = s_t_plus_1\n",
    "        total_steps += 1\n",
    "        steps_in_ep += 1\n",
    "\n",
    "        if done: break\n",
    "\n",
    "    agent.increment_episode()\n",
    "    print('Episode %2i, Reward: %7.3f, Steps: %i'%(ep, total_reward, steps_in_ep))\n",
    "\n",
    "# Finalize and upload results\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "[Pendulum-v0] No such video file /tmp/pendulum-v0/openaigym.video.0.4323.video000000.mp4. (HINT: Your video recorder may have broken midway through the run. You can check this with `video_recorder.functional`.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-83359d63feb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/pendulum-v0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MY_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tom/anaconda2/lib/python2.7/site-packages/gym/scoreboard/api.pyc\u001b[0m in \u001b[0;36mupload\u001b[0;34m(training_dir, algorithm_id, writeup, tags, benchmark_id, api_key, ignore_open_monitors, skip_videos)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mignore_open_monitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_open_monitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mskip_videos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_videos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tom/anaconda2/lib/python2.7/site-packages/gym/scoreboard/api.pyc\u001b[0m in \u001b[0;36m_upload\u001b[0;34m(training_dir, algorithm_id, writeup, benchmark_run_id, api_key, ignore_open_monitors, skip_videos)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Still have an open monitor on {}. You must run 'env.close()' before uploading.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0menv_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_episode_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_videos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0menv_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'env_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mtraining_episode_batch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_video_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tom/anaconda2/lib/python2.7/site-packages/gym/scoreboard/api.pyc\u001b[0m in \u001b[0;36mupload_training_data\u001b[0;34m(training_dir, api_key, skip_videos)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mtraining_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_training_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mtraining_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tom/anaconda2/lib/python2.7/site-packages/gym/scoreboard/api.pyc\u001b[0m in \u001b[0;36mupload_training_video\u001b[0;34m(videos, api_key, env_id)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m\"\"\"videos: should be list of (video_path, metadata_path) tuples\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marchive_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mwrite_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0marchive_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tom/anaconda2/lib/python2.7/site-packages/gym/scoreboard/api.pyc\u001b[0m in \u001b[0;36mwrite_archive\u001b[0;34m(videos, archive_file, env_id)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}] No such video file {}. (HINT: Your video recorder may have broken midway through the run. You can check this with `video_recorder.functional`.)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}] No such metadata file {}. (HINT: this should be automatically created when using a VideoRecorder instance.)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: [Pendulum-v0] No such video file /tmp/pendulum-v0/openaigym.video.0.4323.video000000.mp4. (HINT: Your video recorder may have broken midway through the run. You can check this with `video_recorder.functional`.)"
     ]
    }
   ],
   "source": [
    "gym.upload('/tmp/pendulum-v0', api_key='MY_API_KEY')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
